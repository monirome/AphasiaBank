{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables: change the three dots for the path where the transcripts in chat format can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"C:/Users/romer/OneDrive/Desktop/aphasia\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylangacq as pla\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transcriptions\n",
    "\n",
    "def read_chat_files(file_directory):\n",
    "    ds = pla.read_chat(file_directory)\n",
    "    files=ds.file_paths()\n",
    "\n",
    "    #Time Mark (milisecond)\n",
    "    cols = ['mark_start','mark_end']\n",
    "    lst = []\n",
    "    for i in range(len(ds.utterances(participants=\"PAR\"))):\n",
    "        lst.append(ds.utterances(participants=\"PAR\")[i].time_marks)\n",
    "    df = pd.DataFrame(lst, columns=cols) #create datrafame\n",
    "\n",
    "    #pacient transcription\n",
    "    transcriptions=[]\n",
    "    for i in range(len(ds.utterances(participants=\"PAR\"))):\n",
    "        transcriptions.append(ds.utterances(participants=\"PAR\")[i].tiers['PAR'][:-16])\n",
    "    df=df.assign(transcriptions=transcriptions)\n",
    "\n",
    "    #pacient information\n",
    "    v_sex=[]\n",
    "    v_age=[]\n",
    "    v_WAB_AQ=[]\n",
    "    v_file_name=[]\n",
    "    v_aphasia_type=[]\n",
    "    for f in files: \n",
    "        ds2=pla.read_chat(f)\n",
    "        participant=ds2.words(participants=\"PAR\",by_utterances=True)\n",
    "        size=len(participant)\n",
    "        for j in range(size):\n",
    "            header=ds2.headers()\n",
    "            sex=header[0]['Participants']['PAR']['sex'] #sex information\n",
    "            age=header[0]['Participants']['PAR']['age'] #age information\n",
    "            WAB_AQ=header[0]['Participants']['PAR']['custom'] #WAB_AQ information\n",
    "            aphasia_type=header[0]['Participants']['PAR']['group'] #fluency_speech information\n",
    "            v_sex.append(sex)\n",
    "            v_age.append(age)\n",
    "            v_WAB_AQ.append(WAB_AQ)\n",
    "            v_aphasia_type.append(aphasia_type)\n",
    "            for k in range (len(ds2.file_paths())):\n",
    "                v_file_name.append(ds2.file_paths()[k]) #file name \n",
    "\n",
    "                \n",
    "    df=df.assign(sex=v_sex)\n",
    "    df=df.assign(age=v_age)\n",
    "    df=df.assign(file=v_file_name)\n",
    "    df=df.assign(WAB_AQ=v_WAB_AQ)\n",
    "    df=df.assign(aphasia_type=v_aphasia_type)\n",
    "\n",
    "    df['age'] = df['age'].str[:2] #remove the months\n",
    "    path_len = len(filepath) + 1\n",
    "    df['file'] = df['file'].str[path_len:] #the number of str[] is the lenght of your directory\n",
    "    df['file'] = df['file'].str[:-4]+'.wav' #file format \n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_chat_files(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mark_start</th>\n",
       "      <th>mark_end</th>\n",
       "      <th>transcriptions</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>file</th>\n",
       "      <th>WAB_AQ</th>\n",
       "      <th>aphasia_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9430</td>\n",
       "      <td>12876</td>\n",
       "      <td>yeah well &amp;=laughs +</td>\n",
       "      <td>female</td>\n",
       "      <td>69</td>\n",
       "      <td>ACWT01a.wav</td>\n",
       "      <td>63.9</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15181</td>\n",
       "      <td>20445</td>\n",
       "      <td>I yeah you_know &amp;=nods &amp;=ges:so_so dada@b dada...</td>\n",
       "      <td>female</td>\n",
       "      <td>69</td>\n",
       "      <td>ACWT01a.wav</td>\n",
       "      <td>63.9</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24756</td>\n",
       "      <td>33655</td>\n",
       "      <td>yes ‡ &amp;j &amp;=traces:two it's two thousand &amp;=trac...</td>\n",
       "      <td>female</td>\n",
       "      <td>69</td>\n",
       "      <td>ACWT01a.wav</td>\n",
       "      <td>63.9</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33655</td>\n",
       "      <td>34070</td>\n",
       "      <td>no</td>\n",
       "      <td>female</td>\n",
       "      <td>69</td>\n",
       "      <td>ACWT01a.wav</td>\n",
       "      <td>63.9</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34070</td>\n",
       "      <td>43822</td>\n",
       "      <td>after &amp;n (.) New_Dear's_Day [: New_Year's_Day]...</td>\n",
       "      <td>female</td>\n",
       "      <td>69</td>\n",
       "      <td>ACWT01a.wav</td>\n",
       "      <td>63.9</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>1990162</td>\n",
       "      <td>2002963</td>\n",
       "      <td>the &amp;+t tour bus is coming +... \u0015</td>\n",
       "      <td>female</td>\n",
       "      <td>83</td>\n",
       "      <td>ACWT12a.wav</td>\n",
       "      <td>79.5</td>\n",
       "      <td>Conduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>2002963</td>\n",
       "      <td>2003536</td>\n",
       "      <td>I lost it . \u0015</td>\n",
       "      <td>female</td>\n",
       "      <td>83</td>\n",
       "      <td>ACWT12a.wav</td>\n",
       "      <td>79.5</td>\n",
       "      <td>Conduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>2014840</td>\n",
       "      <td>2029746</td>\n",
       "      <td>the tour bus is coming &amp;+dow &amp;+a a^round [*] t...</td>\n",
       "      <td>female</td>\n",
       "      <td>83</td>\n",
       "      <td>ACWT12a.wav</td>\n",
       "      <td>79.5</td>\n",
       "      <td>Conduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>2069730</td>\n",
       "      <td>2070293</td>\n",
       "      <td>okay . \u0015</td>\n",
       "      <td>female</td>\n",
       "      <td>83</td>\n",
       "      <td>ACWT12a.wav</td>\n",
       "      <td>79.5</td>\n",
       "      <td>Conduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>2077371</td>\n",
       "      <td>2082234</td>\n",
       "      <td>the dog raced [: chased] [*] the &amp;+g cat up th...</td>\n",
       "      <td>female</td>\n",
       "      <td>83</td>\n",
       "      <td>ACWT12a.wav</td>\n",
       "      <td>79.5</td>\n",
       "      <td>Conduction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2047 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mark_start  mark_end                                     transcriptions  \\\n",
       "0           9430     12876                               yeah well &=laughs +   \n",
       "1          15181     20445  I yeah you_know &=nods &=ges:so_so dada@b dada...   \n",
       "2          24756     33655  yes ‡ &j &=traces:two it's two thousand &=trac...   \n",
       "3          33655     34070                                                 no   \n",
       "4          34070     43822  after &n (.) New_Dear's_Day [: New_Year's_Day]...   \n",
       "...          ...       ...                                                ...   \n",
       "2042     1990162   2002963                  the &+t tour bus is coming +... \u0015   \n",
       "2043     2002963   2003536                                      I lost it . \u0015   \n",
       "2044     2014840   2029746  the tour bus is coming &+dow &+a a^round [*] t...   \n",
       "2045     2069730   2070293                                           okay . \u0015   \n",
       "2046     2077371   2082234  the dog raced [: chased] [*] the &+g cat up th...   \n",
       "\n",
       "         sex age         file WAB_AQ aphasia_type  \n",
       "0     female  69  ACWT01a.wav   63.9        Broca  \n",
       "1     female  69  ACWT01a.wav   63.9        Broca  \n",
       "2     female  69  ACWT01a.wav   63.9        Broca  \n",
       "3     female  69  ACWT01a.wav   63.9        Broca  \n",
       "4     female  69  ACWT01a.wav   63.9        Broca  \n",
       "...      ...  ..          ...    ...          ...  \n",
       "2042  female  83  ACWT12a.wav   79.5   Conduction  \n",
       "2043  female  83  ACWT12a.wav   79.5   Conduction  \n",
       "2044  female  83  ACWT12a.wav   79.5   Conduction  \n",
       "2045  female  83  ACWT12a.wav   79.5   Conduction  \n",
       "2046  female  83  ACWT12a.wav   79.5   Conduction  \n",
       "\n",
       "[2047 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New metric: 'file_cut', where the start and duration of each transcription will be reflected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_cut -> file_start_duration \n",
    "\n",
    "v_file_cut=[]\n",
    "for i in range(len(df)):\n",
    "    start=((pd.to_numeric(df['mark_start'][i]))/1000)\n",
    "    duration=((pd.to_numeric(df['mark_end'][i]))-(pd.to_numeric(df['mark_start'][i])))/1000\n",
    "    file=df['file'][i][:-4]\n",
    "    file_cut=f\"\"\"{file}_{start}_{duration}.wav\"\"\"\n",
    "    v_file_cut.append(file_cut)\n",
    "df=df.assign(file_cut=v_file_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New metric: 'WAB_AQ_category', type of severity of the patient's aphasia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAB_AQ_category -> aphasia type \n",
    "\n",
    "df.loc[(pd.to_numeric(df['WAB_AQ'])>= 0) & (pd.to_numeric(df['WAB_AQ'])<=25), 'WAB_AQ_category'] = 'Very severe'\n",
    "df.loc[(pd.to_numeric(df['WAB_AQ'])> 25) & (pd.to_numeric(df['WAB_AQ'])<=50), 'WAB_AQ_category'] = 'Severe'\n",
    "df.loc[(pd.to_numeric(df['WAB_AQ'])> 50) & (pd.to_numeric(df['WAB_AQ'])<=75), 'WAB_AQ_category'] = 'Moderate'\n",
    "df.loc[(pd.to_numeric(df['WAB_AQ'])> 75) , 'WAB_AQ_category'] = 'Mild'\n",
    "df.loc[np.isnan(pd.to_numeric(df['WAB_AQ'])) , 'WAB_AQ_category'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New metric: 'fluency_speech' is the patient's speech fluency based on the type of aphasia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fluency_speech -> speech fluency based on aphasia_type\n",
    "\n",
    "df.loc[((df['aphasia_type'])== 'Anomic') | ((df['aphasia_type'])== 'Conduction') | ((df['aphasia_type'])== 'Fluent')| ((df['aphasia_type'])== 'Wernicke')| ((df['aphasia_type'])== 'TransSensory'), 'fluency_speech'] = 'Fluent'\n",
    "df.loc[((df['aphasia_type'])== 'Broca') | ((df['aphasia_type'])== 'Global') | ((df['aphasia_type'])== 'TransMotor'), 'fluency_speech'] = 'Non Fluent'\n",
    "df.loc[((df['aphasia_type'])== 'NotAphasicByWAB') , 'fluency_speech'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"filterWordsPhonetics\" function changes the words written with phonemes for those that appear below between correctly written brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterWordsPhonetic(string):\n",
    "    while str(string).find(\"[:\")>0:\n",
    "        positionbracket = string.find(\"[:\")\n",
    "        if string[positionbracket -1] != \" \": # If not an space before [:, add it\n",
    "            string = string[:positionbracket] + \" \" + string[positionbracket:]\n",
    "        \n",
    "        list_words=string.split(\" \")\n",
    "        try: \n",
    "            corchete_init=list_words.index(\"[:\")\n",
    "        except:\n",
    "            corchete_init=list_words.index(\"[::\") # Sometimes they write [:: instead of [:\n",
    "        \n",
    "        list_words[corchete_init-1] = list_words[corchete_init+1][0:-1] # change the bad word for good word\n",
    "        del list_words[corchete_init:corchete_init+4] \n",
    "        string = \" \".join(list_words)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transcriptions'] = df['transcriptions'].map(filterWordsPhonetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A massive weird character cleanup is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�\\‡\\„\\$\\^\\/\\//\\0\\↓\\≠\\↑]' \n",
    "for i in range(len(df['transcriptions'])):\n",
    "    df['transcriptions'][i]=re.sub(chars_to_ignore_regex,\"\", str(df[\"transcriptions\"][i])).lower()\n",
    "\n",
    "    df['transcriptions'][i]=re.sub('\\+<', ' ',str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('&=laughs','<LAU>',str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('&=chuckles','<LAU>',str(df[\"transcriptions\"][i]))\n",
    "    \n",
    "    df['transcriptions'][i]=re.sub('\\&=\\w*:\\w*_\\w*','',str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('[\\[].*?[\\]]','',str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\&=[a-z]*:[a-z]*','',str(df[\"transcriptions\"][i])) #quita las trasncripciones tipo &=word:word\n",
    "\n",
    "    df['transcriptions'][i]=re.sub('&-.([a-z]*)','F',str(df[\"transcriptions\"][i])) #quita las trasncripciones tipo &-word\n",
    "    df['transcriptions'][i]=re.sub('&.([a-z]*)','F',str(df[\"transcriptions\"][i])) #quita las trasncripciones tipo &word\n",
    "    \n",
    "    df['transcriptions'][i]=re.sub('\\+', ' ',str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('[/&=] *','S' ',str(df[\"transcriptions\"][i]))\n",
    "\n",
    "    df['transcriptions'][i]=re.sub('dada@b',\"F\", str(df[\"transcriptions\"][i]))    \n",
    "    df['transcriptions'][i]=re.sub('_',' ',df[\"transcriptions\"][i] )\n",
    "    df['transcriptions'][i]=re.sub('\\x15',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\)',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\(',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[  gra',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('   ', ' ', str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('  ', ' ', str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub(r'[0-9]',\"\", df[\"transcriptions\"][i])\n",
    "    df['transcriptions'][i]=re.sub('xn', '', str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub(r\"  \",\" \", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('blublublubluhb',\"S\", df[\"transcriptions\"][i])    \n",
    "    df['transcriptions'][i]=re.sub('www',\"\", str(df[\"transcriptions\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['transcriptions'])):\n",
    "    df['transcriptions'][i]=re.sub('<seeing>',\"seeing\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<seeing them>',\"seeing\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<wanna>',\"wanna\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<that>',\"that\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<yeah>',\"yeah\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<okay>',\"okay\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<just>',\"just\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<with>',\"with\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<raindrops>',\"raindrops\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<and>',\"and\", str(df[\"transcriptions\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['transcriptions'])):\n",
    "    df['transcriptions'][i]=re.sub('\\[<spn',\"S\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[<',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[ gr',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[ g',\"\", str(df[\"transcriptions\"][i]))\n",
    "    \n",
    "    df['transcriptions'][i]=re.sub('\\[ jar',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[ ja',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[ j',\"\", str(df[\"transcriptions\"][i]))\n",
    "    \n",
    "    df['transcriptions'][i]=re.sub('\\[ exc',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[ ex',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[ e',\"\", str(df[\"transcriptions\"][i]))\n",
    "    \n",
    "    df['transcriptions'][i]=re.sub('\\[ es',\"\", str(df[\"transcriptions\"][i]))\n",
    "    \n",
    "    df['transcriptions'][i]=re.sub('\\[ ci',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[ c',\"\", str(df[\"transcriptions\"][i]))\n",
    "    \n",
    "    df['transcriptions'][i]=re.sub('gram]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('pn]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('nk]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('srgcpro]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('belt]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('sr]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('suk]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('/snan/s',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<xxx>',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<xxx',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('xxx>',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('@',\"\", str(df[\"transcriptions\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['transcriptions'] = df['transcriptions'].apply(lambda s: ' '.join(i for i in s.split(' ') if i != 'x'))\n",
    "df['transcriptions'] = df['transcriptions'].apply(lambda s: ' '.join(i for i in s.split(' ') if i != 'xx'))\n",
    "df['transcriptions'] = df['transcriptions'].apply(lambda s: ' '.join(i for i in s.split(' ') if i != 'xxx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "p='é|æ|ɑ|ɔ|ɕ|ç|ḏ|ḍ|ð|ə|ɚ|ɛ|ɝ|ḡ|ʰ|ḥ|ḫ|ẖ|ɪ|ỉ|ɨ|ʲ|ǰ|ḳ|ḵ|ḷ|ɬ|ɫ|ŋ|ṇ|ɲ|ɴ|ŏ|ɸ|θ|p̅|þ|ɹ|ɾ|ʀ|ʁ|ṛ|š|ś|ṣ|ʃ|ṭ|ṯ|ʨ|tʂ|ʊ|ŭ|ü|ʌ|ɣ|ʍ|χ|ʸ|ʎ|ẓ|ž|ʒ|’|‘|ʔ|ʕ|∬|↫'\n",
    "df=df.loc[~df['transcriptions'].str.contains(p, regex=True)]  #remove words with phonemes\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[~df[\"transcriptions\"].isnull()] #remove nulls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"transcriptions\"] = df[\"transcriptions\"].str.rstrip() #remove blanks at the beginning \n",
    "df[\"transcriptions\"] = df[\"transcriptions\"].str.lstrip() #remove blanks at the end "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all the characters of the transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " \"'\",\n",
       " '<',\n",
       " '>',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '̝'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(\" \".join(df[\"transcriptions\"].values))\n",
    "# df[df[\"transcriptions\"].str.contains(\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataset in a folder for using in the following scipts \n",
    "df.to_csv (r'filepath\\clean_dataset.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
