{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables: change the three dots for the path where the transcripts in chat format can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"...\" #path where the transcripts in chat format can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylangacq as pla\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transcriptions\n",
    "\n",
    "def read_chat_files(file_directory):\n",
    "    ds = pla.read_chat(file_directory)\n",
    "    files=ds.file_paths()\n",
    "\n",
    "    #Time Mark (milisecond)\n",
    "    cols = ['mark_start','mark_end']\n",
    "    lst = []\n",
    "    for i in range(len(ds.utterances(participants=\"PAR\"))):\n",
    "        lst.append(ds.utterances(participants=\"PAR\")[i].time_marks)\n",
    "    df = pd.DataFrame(lst, columns=cols) #create datrafame\n",
    "\n",
    "    #pacient transcription\n",
    "    transcriptions=[]\n",
    "    for i in range(len(ds.utterances(participants=\"PAR\"))):\n",
    "        transcriptions.append(ds.utterances(participants=\"PAR\")[i].tiers['PAR'][:-16])\n",
    "    df=df.assign(transcriptions=transcriptions)\n",
    "\n",
    "    #pacient information\n",
    "    v_sex=[]\n",
    "    v_age=[]\n",
    "    v_WAB_AQ=[]\n",
    "    v_file_name=[]\n",
    "    v_aphasia_type=[]\n",
    "    for f in files: \n",
    "        ds2=pla.read_chat(f)\n",
    "        participant=ds2.words(participants=\"PAR\",by_utterances=True)\n",
    "        size=len(participant)\n",
    "        for j in range(size):\n",
    "            header=ds2.headers()\n",
    "            sex=header[0]['Participants']['PAR']['sex'] #sex information\n",
    "            age=header[0]['Participants']['PAR']['age'] #age information\n",
    "            WAB_AQ=header[0]['Participants']['PAR']['custom'] #WAB_AQ information\n",
    "            aphasia_type=header[0]['Participants']['PAR']['group'] #fluency_speech information\n",
    "            v_sex.append(sex)\n",
    "            v_age.append(age)\n",
    "            v_WAB_AQ.append(WAB_AQ)\n",
    "            v_aphasia_type.append(aphasia_type)\n",
    "            for k in range (len(ds2.file_paths())):\n",
    "                v_file_name.append(ds2.file_paths()[k]) #file name \n",
    "\n",
    "                \n",
    "    df=df.assign(sex=v_sex)\n",
    "    df=df.assign(age=v_age)\n",
    "    df=df.assign(file=v_file_name)\n",
    "    df=df.assign(WAB_AQ=v_WAB_AQ)\n",
    "    df=df.assign(aphasia_type=v_aphasia_type)\n",
    "\n",
    "    df['age'] = df['age'].str[:2] #remove the months\n",
    "    df['file'] = df['file'].str[56:] #remove the directory ##the number of str[] is the lenght of your directory\n",
    "    df['file'] = df['file'].str[:-4]+'.wav' #file format \n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_chat_files(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mark_start</th>\n",
       "      <th>mark_end</th>\n",
       "      <th>transcriptions</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>file</th>\n",
       "      <th>WAB_AQ</th>\n",
       "      <th>aphasia_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9430.0</td>\n",
       "      <td>12876.0</td>\n",
       "      <td>yeah well &amp;=laughs +</td>\n",
       "      <td>female</td>\n",
       "      <td>69.0</td>\n",
       "      <td>ACWT01a.wav</td>\n",
       "      <td>63.9</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15181.0</td>\n",
       "      <td>20445.0</td>\n",
       "      <td>I yeah you_know &amp;=nods &amp;=ges:so_so dada@b dada...</td>\n",
       "      <td>female</td>\n",
       "      <td>69.0</td>\n",
       "      <td>ACWT01a.wav</td>\n",
       "      <td>63.9</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24756.0</td>\n",
       "      <td>33655.0</td>\n",
       "      <td>yes ‡ &amp;j &amp;=traces:two it's two thousand &amp;=trac...</td>\n",
       "      <td>female</td>\n",
       "      <td>69.0</td>\n",
       "      <td>ACWT01a.wav</td>\n",
       "      <td>63.9</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33655.0</td>\n",
       "      <td>34070.0</td>\n",
       "      <td>no</td>\n",
       "      <td>female</td>\n",
       "      <td>69.0</td>\n",
       "      <td>ACWT01a.wav</td>\n",
       "      <td>63.9</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34070.0</td>\n",
       "      <td>43822.0</td>\n",
       "      <td>after &amp;n (.) New_Dear's_Day [: New_Year's_Day]...</td>\n",
       "      <td>female</td>\n",
       "      <td>69.0</td>\n",
       "      <td>ACWT01a.wav</td>\n",
       "      <td>63.9</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78026</th>\n",
       "      <td>909216.0</td>\n",
       "      <td>911714.0</td>\n",
       "      <td>&amp;+s fold it &amp;=ges:together .</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0</td>\n",
       "      <td>wright207a.wav</td>\n",
       "      <td>61.5</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78027</th>\n",
       "      <td>911714.0</td>\n",
       "      <td>914909.0</td>\n",
       "      <td>it's pretty good &amp;=head:yes . [+ exc]</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0</td>\n",
       "      <td>wright207a.wav</td>\n",
       "      <td>61.5</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78028</th>\n",
       "      <td>914909.0</td>\n",
       "      <td>915458.0</td>\n",
       "      <td>yeah . [+ exc]</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0</td>\n",
       "      <td>wright207a.wav</td>\n",
       "      <td>61.5</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78029</th>\n",
       "      <td>915458.0</td>\n",
       "      <td>917189.0</td>\n",
       "      <td>yeah ‡ pretty good . [+ exc]</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0</td>\n",
       "      <td>wright207a.wav</td>\n",
       "      <td>61.5</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78030</th>\n",
       "      <td>917189.0</td>\n",
       "      <td>918788.0</td>\n",
       "      <td>I like it . [+ exc]</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0</td>\n",
       "      <td>wright207a.wav</td>\n",
       "      <td>61.5</td>\n",
       "      <td>Broca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78031 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mark_start  mark_end  \\\n",
       "0          9430.0   12876.0   \n",
       "1         15181.0   20445.0   \n",
       "2         24756.0   33655.0   \n",
       "3         33655.0   34070.0   \n",
       "4         34070.0   43822.0   \n",
       "...           ...       ...   \n",
       "78026    909216.0  911714.0   \n",
       "78027    911714.0  914909.0   \n",
       "78028    914909.0  915458.0   \n",
       "78029    915458.0  917189.0   \n",
       "78030    917189.0  918788.0   \n",
       "\n",
       "                                          transcriptions     sex   age  \\\n",
       "0                                   yeah well &=laughs +  female  69.0   \n",
       "1      I yeah you_know &=nods &=ges:so_so dada@b dada...  female  69.0   \n",
       "2      yes ‡ &j &=traces:two it's two thousand &=trac...  female  69.0   \n",
       "3                                                     no  female  69.0   \n",
       "4      after &n (.) New_Dear's_Day [: New_Year's_Day]...  female  69.0   \n",
       "...                                                  ...     ...   ...   \n",
       "78026                       &+s fold it &=ges:together .  female  63.0   \n",
       "78027              it's pretty good &=head:yes . [+ exc]  female  63.0   \n",
       "78028                                     yeah . [+ exc]  female  63.0   \n",
       "78029                       yeah ‡ pretty good . [+ exc]  female  63.0   \n",
       "78030                                I like it . [+ exc]  female  63.0   \n",
       "\n",
       "                 file  WAB_AQ aphasia_type  \n",
       "0         ACWT01a.wav    63.9        Broca  \n",
       "1         ACWT01a.wav    63.9        Broca  \n",
       "2         ACWT01a.wav    63.9        Broca  \n",
       "3         ACWT01a.wav    63.9        Broca  \n",
       "4         ACWT01a.wav    63.9        Broca  \n",
       "...               ...     ...          ...  \n",
       "78026  wright207a.wav    61.5        Broca  \n",
       "78027  wright207a.wav    61.5        Broca  \n",
       "78028  wright207a.wav    61.5        Broca  \n",
       "78029  wright207a.wav    61.5        Broca  \n",
       "78030  wright207a.wav    61.5        Broca  \n",
       "\n",
       "[78031 rows x 8 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New metric: 'file_cut', where the start and duration of each transcription will be reflected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_cut -> file_start_duration \n",
    "\n",
    "v_file_cut=[]\n",
    "for i in range(len(df)):\n",
    "    start=((pd.to_numeric(df['mark_start'][i]))/1000)\n",
    "    duration=((pd.to_numeric(df['mark_end'][i]))-(pd.to_numeric(df['mark_start'][i])))/1000\n",
    "    file=df['file'][i][:-4]\n",
    "    file_cut=f\"\"\"{file}_{start}_{duration}.wav\"\"\"\n",
    "    v_file_cut.append(file_cut)\n",
    "df=df.assign(file_cut=v_file_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New metric: 'WAB_AQ_category', type of severity of the patient's aphasia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAB_AQ_category -> aphasia type \n",
    "\n",
    "df.loc[(pd.to_numeric(df['WAB_AQ'])>= 0) & (pd.to_numeric(df['WAB_AQ'])<=25), 'WAB_AQ_category'] = 'Very severe'\n",
    "df.loc[(pd.to_numeric(df['WAB_AQ'])> 25) & (pd.to_numeric(df['WAB_AQ'])<=50), 'WAB_AQ_category'] = 'Severe'\n",
    "df.loc[(pd.to_numeric(df['WAB_AQ'])> 50) & (pd.to_numeric(df['WAB_AQ'])<=75), 'WAB_AQ_category'] = 'Moderate'\n",
    "df.loc[(pd.to_numeric(df['WAB_AQ'])> 75) , 'WAB_AQ_category'] = 'Mild'\n",
    "df.loc[np.isnan(pd.to_numeric(df['WAB_AQ'])) , 'WAB_AQ_category'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New metric: 'fluency_speech' is the patient's speech fluency based on the type of aphasia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fluency_speech -> speech fluency based on aphasia_type\n",
    "\n",
    "df.loc[((df['aphasia_type'])== 'Anomic') | ((df['aphasia_type'])== 'Conduction') | ((df['aphasia_type'])== 'Fluent')| ((df['aphasia_type'])== 'Wernicke')| ((df['aphasia_type'])== 'TransSensory'), 'fluency_speech'] = 'Fluent'\n",
    "df.loc[((df['aphasia_type'])== 'Broca') | ((df['aphasia_type'])== 'Global') | ((df['aphasia_type'])== 'TransMotor'), 'fluency_speech'] = 'Non Fluent'\n",
    "df.loc[((df['aphasia_type'])== 'NotAphasicByWAB') , 'fluency_speech'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"filterWordsPhonetics\" function changes the words written with phonemes for those that appear below between correctly written brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterWordsPhonetic(string):\n",
    "    while str(string).find(\"[:\")>0:\n",
    "        positionbracket = string.find(\"[:\")\n",
    "        if string[positionbracket -1] != \" \": # If not an space before [:, add it\n",
    "            string = string[:positionbracket] + \" \" + string[positionbracket:]\n",
    "        \n",
    "        list_words=string.split(\" \")\n",
    "        try: \n",
    "            corchete_init=list_words.index(\"[:\")\n",
    "        except:\n",
    "            corchete_init=list_words.index(\"[::\") # Sometimes they write [:: instead of [:\n",
    "        \n",
    "        list_words[corchete_init-1] = list_words[corchete_init+1][0:-1] # change the bad word for good word\n",
    "        del list_words[corchete_init:corchete_init+4] \n",
    "        string = \" \".join(list_words)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transcriptions'] = df['transcriptions'].map(filterWordsPhonetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A massive weird character cleanup is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�\\‡\\„\\$\\^\\/\\//\\0\\↓\\≠\\↑]' \n",
    "for i in range(len(df['transcriptions'])):\n",
    "    df['transcriptions'][i]=re.sub(chars_to_ignore_regex,\"\", str(df[\"transcriptions\"][i])).lower()\n",
    "\n",
    "    df['transcriptions'][i]=re.sub('\\+<', ' ',str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('&=laughs','<LAU>',str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('&=chuckles','<LAU>',str(df[\"transcriptions\"][i]))\n",
    "    \n",
    "    df['transcriptions'][i]=re.sub('\\&=\\w*:\\w*_\\w*','',str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('[\\[].*?[\\]]','',str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\&=[a-z]*:[a-z]*','',str(df[\"transcriptions\"][i])) #quita las trasncripciones tipo &=word:word\n",
    "\n",
    "    df['transcriptions'][i]=re.sub('&-.([a-z]*)','<FLR>',str(df[\"transcriptions\"][i])) #quita las trasncripciones tipo &-word\n",
    "    df['transcriptions'][i]=re.sub('&.([a-z]*)','<FLR>',str(df[\"transcriptions\"][i])) #quita las trasncripciones tipo &word\n",
    "    \n",
    "    df['transcriptions'][i]=re.sub('\\+', ' ',str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('[/&=] *','<SPN> ',str(df[\"transcriptions\"][i]))\n",
    "\n",
    "    df['transcriptions'][i]=re.sub('dada@b',\"<FLR>\", str(df[\"transcriptions\"][i]))    \n",
    "    df['transcriptions'][i]=re.sub(chars_to_ignore_regex,\"\", df[\"transcriptions\"][i]).lower()\n",
    "    df['transcriptions'][i]=re.sub('_',' ',df[\"transcriptions\"][i] )\n",
    "    df['transcriptions'][i]=re.sub('\\x15',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\)',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\(',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[  gra',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('   ', ' ', str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('  ', ' ', str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub(r'[0-9]',\"\", df[\"transcriptions\"][i])\n",
    "    df['transcriptions'][i]=re.sub('xn', '', str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub(r\"  \",\" \", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('blublublubluhb',\"<SPN>\", df[\"transcriptions\"][i])    \n",
    "    df['transcriptions'][i]=re.sub('www',\"\", str(df[\"transcriptions\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['transcriptions'])):\n",
    "    df['transcriptions'][i]=re.sub('<seeing>',\"seeing\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<seeing them>',\"seeing\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<wanna>',\"wanna\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<that>',\"that\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<yeah>',\"yeah\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<okay>',\"okay\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<just>',\"just\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<with>',\"with\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<raindrops>',\"raindrops\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<and>',\"and\", str(df[\"transcriptions\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['transcriptions'])):\n",
    "    df['transcriptions'][i]=re.sub('\\[<spn',\"<spn>\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[<',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[ gr',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[ g',\"\", str(df[\"transcriptions\"][i]))\n",
    "    \n",
    "    df['transcriptions'][i]=re.sub('\\[ jar',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[ ja',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[ j',\"\", str(df[\"transcriptions\"][i]))\n",
    "    \n",
    "    df['transcriptions'][i]=re.sub('\\[ exc',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[ ex',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[ e',\"\", str(df[\"transcriptions\"][i]))\n",
    "    \n",
    "    df['transcriptions'][i]=re.sub('\\[ es',\"\", str(df[\"transcriptions\"][i]))\n",
    "    \n",
    "    df['transcriptions'][i]=re.sub('\\[ ci',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\[ c',\"\", str(df[\"transcriptions\"][i]))\n",
    "    \n",
    "    df['transcriptions'][i]=re.sub('gram]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('pn]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('nk]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('srgcpro]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('belt]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('sr]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('suk]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('\\]',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('/snan/s',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<xxx>',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('<xxx',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('xxx>',\"\", str(df[\"transcriptions\"][i]))\n",
    "    df['transcriptions'][i]=re.sub('@',\"\", str(df[\"transcriptions\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['transcriptions'] = df['transcriptions'].apply(lambda s: ' '.join(i for i in s.split(' ') if i != 'x'))\n",
    "df['transcriptions'] = df['transcriptions'].apply(lambda s: ' '.join(i for i in s.split(' ') if i != 'xx'))\n",
    "df['transcriptions'] = df['transcriptions'].apply(lambda s: ' '.join(i for i in s.split(' ') if i != 'xxx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "p='é|æ|ɑ|ɔ|ɕ|ç|ḏ|ḍ|ð|ə|ɚ|ɛ|ɝ|ḡ|ʰ|ḥ|ḫ|ẖ|ɪ|ỉ|ɨ|ʲ|ǰ|ḳ|ḵ|ḷ|ɬ|ɫ|ŋ|ṇ|ɲ|ɴ|ŏ|ɸ|θ|p̅|þ|ɹ|ɾ|ʀ|ʁ|ṛ|š|ś|ṣ|ʃ|ṭ|ṯ|ʨ|tʂ|ʊ|ŭ|ü|ʌ|ɣ|ʍ|χ|ʸ|ʎ|ẓ|ž|ʒ|’|‘|ʔ|ʕ|∬|↫'\n",
    "df=df.loc[~df['transcriptions'].str.contains(p, regex=True)]  #remove words with phonemes\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[~df[\"transcriptions\"].isnull()] #remove nulls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"transcriptions\"] = df[\"transcriptions\"].str.rstrip() #remove blanks at the beginning \n",
    "df[\"transcriptions\"] = df[\"transcriptions\"].str.lstrip() #remove blanks at the end "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all the characters of the transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " \"'\",\n",
       " '<',\n",
       " '>',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '̝'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(\" \".join(df[\"transcriptions\"].values))\n",
    "# df[df[\"transcriptions\"].str.contains(\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataset in a folder for using in the following scipts \n",
    "df.to_csv (r'filepath\\clean_dataset.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
